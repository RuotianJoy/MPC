# MPC-RDF 图分区算法

MPC (Minimum Property-Cut) 是一种专为RDF图设计的分区算法，通过最小化跨分区谓词（属性）的数量来实现高效的分布式查询处理。与传统的图分区算法不同，MPC算法专注于减少跨分区边的种类（谓词/属性），而不仅仅是边的数量。

## 目录

- [原理介绍](#原理介绍)
- [算法流程](#算法流程)
- [安装和运行](#安装和运行)
- [示例说明](#示例说明)
- [可视化界面](#可视化界面)
- [算法实现细节](#算法实现细节)
- [性能分析](#性能分析)

## 原理介绍

### RDF图分区的挑战

RDF（资源描述框架）数据通常表示为主语-谓词-宾语的三元组集合，形成一个具有丰富语义信息的图结构。在大规模RDF数据管理中，将数据分区存储在多个节点上可以提高查询处理效率。然而，传统的图分区算法通常只关注减少跨分区边的数量，而忽略了RDF图中谓词（属性）的重要性。

### MPC算法核心思想

MPC算法的核心思想是：

1. **最小化跨分区谓词数量**：不同于传统分区算法关注的边数量，MPC专注于减少跨分区的谓词类型数量，因为在SPARQL查询中，谓词通常是重要的连接点。

2. **保持分区大小平衡**：确保每个分区的节点数量相对均衡，避免出现过大或过小的分区。

3. **利用弱连通分量(WCC)分析**：通过分析每个谓词形成的弱连通分量，识别应该放在同一分区的节点组。

## 算法流程

MPC算法的执行流程分为以下几个关键步骤：

1. **图分析与预处理**
   - 加载RDF图数据
   - 为每个实体和谓词分配唯一ID
   - 统计每个谓词的出现频率和连通性

2. **谓词排序与分类**
   - 根据弱连通分量(WCC)的数量对谓词进行排序
   - 将谓词分为小规模、中规模和大规模三类进行处理

3. **图粗化(Coarsening)**
   - 对每个谓词进行弱连通分量分析
   - 标记超过限制大小的连通分量为无效

4. **贪心合并处理**
   - 首先处理小规模谓词，将其连接的节点合并为连通分量
   - 然后按WCC数量排序处理剩余谓词，不断合并节点形成更大的连通分量
   - 记录每一步迭代的分区状态，用于可视化和分析

5. **分区分配**
   - 将合并后的连通分量分配到最终分区
   - 使用贪心算法确保分区大小平衡
   - 计算最终的分区指标，包括切割谓词数量和分区平衡度

## 安装和运行

### 系统要求

- Python 3.7+
- 依赖包见 `requirements.txt`

### 安装步骤

1. 克隆代码库
   ```bash
   git clone https://github.com/your-username/mpc-rdf.git
   cd mpc-rdf
   ```

2. 安装依赖
   ```bash
   pip install -r requirements.txt
   ```

3. 运行Web应用
   ```bash
   python -m src.app
   ```

4. 在浏览器中访问
   ```
   http://localhost:5000
   ```

## 示例说明

我们以一个简单的社交网络RDF数据为例，演示MPC算法的工作过程。

### 示例数据 (sample.ttl)

下面是一个简化的社交网络RDF数据：

```turtle
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix ex: <http://example.org/> .
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .

# 人物
ex:Person1 a foaf:Person ;
    rdfs:label "张三" ;
    foaf:age "28" ;
    foaf:knows ex:Person2, ex:Person3 ;
    ex:livesIn ex:City1 ;
    ex:worksAt ex:Company1 .

ex:Person2 a foaf:Person ;
    rdfs:label "李四" ;
    foaf:age "32" ;
    foaf:knows ex:Person1, ex:Person3 ;
    ex:livesIn ex:City1 ;
    ex:worksAt ex:Company2 .

ex:Person3 a foaf:Person ;
    rdfs:label "王五" ;
    foaf:age "45" ;
    foaf:knows ex:Person1, ex:Person2 ;
    ex:livesIn ex:City2 ;
    ex:worksAt ex:Company1 .

# 城市和公司
ex:City1 a ex:City ;
    rdfs:label "北京" .

ex:City2 a ex:City ;
    rdfs:label "上海" .

ex:Company1 a ex:Company ;
    rdfs:label "科技有限公司" ;
    ex:locatedIn ex:City1 .

ex:Company2 a ex:Company ;
    rdfs:label "金融服务公司" ;
    ex:locatedIn ex:City2 .
```

### 算法执行过程说明

1. **初始状态**: 所有节点未分配到任何分区（标记为-1）
   
2. **第1次迭代**: 处理小规模谓词（边数少于阈值的谓词，如`rdf:type`、`rdfs:label`等），将它们连接的节点合并为初始连通分量。这一步会形成一些临时连通分量，用负数ID标识，如-100、-101等。

3. **第2次迭代**: 分析所有符合条件的中大型谓词，计算每个谓词的弱连通分量(WCC)数量，并按WCC数量排序。

4. **第3次及后续迭代**: 按弱连通分量(WCC)数量从多到少（从最容易分割的开始）处理谓词：
   - 如`foaf:knows`谓词连接了多个人物节点
   - 然后处理`ex:livesIn`连接人物和城市的关系
   - 最后处理`ex:worksAt`连接人物和公司的关系
   
5. **最终分区阶段**: 算法将临时连通分量映射到最终分区，通过贪心算法确保分区大小平衡：
   - 将节点按连通分量分组，计算每个连通分量的大小
   - 从大到小分配连通分量到当前最小的分区
   - 最终形成平衡的分区结构

### 最终结果分析（基于示例数据）

- **分区结构**:
  - 分区0: 可能包含"张三"、"北京"、"科技有限公司"
  - 分区1: 可能包含"王五"、"李四"、"上海"、"金融服务公司"
  
- **切割谓词**: 主要是`foaf:knows`（社交关系）和`ex:worksAt`（工作关系），因为它们跨越了地理位置边界
  
- **算法优势**: 
  - 基于地理位置的查询可以在单个分区内完成
  - 基于公司的查询在大多数情况下也能在单个分区内完成
  - 只有涉及跨地域的社交关系和工作关系的查询需要跨分区处理

## 可视化界面

MPC-RDF系统提供了直观的Web可视化界面：

1. **图可视化**: 通过交互式图显示RDF数据的节点和边，不同颜色代表不同分区

2. **迭代过程动画**: 展示算法每一步的执行过程，高亮显示变化的节点

3. **分区统计**: 显示分区大小和平衡度的统计图表

4. **切割谓词分析**: 展示哪些谓词被切割以及切割频率

![分区可视化示例](https://example.org/partition_visualization.png)

## 算法实现细节

### Greed3策略

当前实现主要采用Greed3算法策略，具体步骤如下：

1. **小规模谓词处理**: 
   - 先处理边数少于阈值的小规模谓词
   - 使用并查集将这些谓词连接的节点合并为连通分量
   - 为每个连通分量分配唯一的临时ID

2. **谓词排序**: 
   - 对于中大型谓词，计算每个谓词形成的弱连通分量(WCC)数量
   - 按WCC数量对谓词进行排序（升序）
   - WCC数量越多，表示该谓词越容易切割

3. **逆序处理谓词**:
   - 从WCC数量最多的谓词开始处理（从数组末尾开始）
   - 这种策略优先处理更容易分割的谓词
   - 每处理一个谓词，更新连通分量结构

4. **连通分量管理**:
   - 维护一个全局的并查集结构跟踪连通分量
   - 实时监控连通分量大小，确保不超过分区大小限制
   - 记录每次迭代后的连通分量状态，用于可视化

### 并查集优化

算法使用了优化的并查集数据结构来跟踪连通分量：

- **路径压缩**: 加速查找操作
- **按秩合并**: 保持并查集树的平衡
- **增量处理**: 实时跟踪连通分量大小，确保不超过限制

## 性能分析

### 时间复杂度

- 图加载与预处理: O(|E|)，其中|E|是边数
- 谓词排序: O(P log P)，其中P是谓词数量
- 图粗化与合并: O(|E| * α(|V|))，其中α是阿克曼函数的反函数，近似常数
- 总体复杂度: O(|E| * α(|V|) + P log P)

### 空间复杂度

- 图存储: O(|V| + |E|)
- 分区映射: O(|V|)
- 连通分量跟踪: O(|V|)
- 总体空间复杂度: O(|V| + |E|)

### 适用场景

MPC算法特别适合以下场景：

- 具有丰富语义信息的知识图谱
- 查询模式中谓词种类是重要考虑因素的应用
- 需要在分布式环境中高效处理SPARQL查询的系统